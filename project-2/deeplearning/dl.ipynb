{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - movielens-latest-small \n",
    "\n",
    "We use movielens-latest-small here as it's more convienient than the 100k one.\n",
    "But we still use only users/movies that were available in the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join('.', 'data')\n",
    "ratings_df = pd.read_csv(os.path.join(data_path, 'ratings.csv'))\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_encoder = LabelEncoder()\n",
    "ratings_df['userEncoded'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "\n",
    "movie_encoder = LabelEncoder()\n",
    "ratings_df['movieEncoded'] = movie_encoder.fit_transform(ratings_df['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 610\n",
      "Number of unique movies: 9724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(85710, 2), (15126, 2), (85710,), (15126,)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ratings_df[['userEncoded', 'movieEncoded']].values\n",
    "y = ratings_df['rating'].values\n",
    "n_users = ratings_df['userEncoded'].nunique()\n",
    "n_movies = ratings_df['movieEncoded'].nunique()\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Number of unique movies: {n_movies}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=2137)\n",
    "[a.shape for a in [X_train, X_test, y_train, y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inputs = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_inputs = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Collaborative ANN\n",
    "\n",
    "Just the user - item relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense, Dropout, Embedding, Flatten, Lambda, Dot, Multiply\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def make_model(n_users, n_movies, embedding_size=50, dense_size=10, min_rating=0.0, max_rating=5.0, join_method='concat'):\n",
    "    user = Input(shape=(1, ))\n",
    "    u_emb = Embedding(\n",
    "        n_users, embedding_size, \n",
    "        embeddings_initializer='he_normal',\n",
    "        embeddings_regularizer=l2(1e-6)\n",
    "    )(user)\n",
    "    u_emb = Flatten()(u_emb)\n",
    "    \n",
    "    movie = Input(shape=(1, ))\n",
    "    m_emb = Embedding(\n",
    "        n_movies, embedding_size, \n",
    "        embeddings_initializer='he_normal',\n",
    "        embeddings_regularizer=l2(1e-6)\n",
    "    )(movie)\n",
    "    m_emb = Flatten()(m_emb)\n",
    "    \n",
    "    if join_method == 'concat':\n",
    "        x = Concatenate()([u_emb, m_emb])\n",
    "    elif join_method == 'product':\n",
    "        x = Multiply()([u_emb, m_emb])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported join method: {join_method}\")\n",
    "    x = Dropout(0.05)(x)\n",
    "    \n",
    "    x = Dense(dense_size, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    # sigmoid output is 0...1 do it must be denormalized to min...max of rating\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    \n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(n_users, n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"concat-%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.9377 - val_loss: 0.7813\n",
      "Epoch 2/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.7715 - val_loss: 0.7585\n",
      "Epoch 3/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.7385 - val_loss: 0.7625\n",
      "Epoch 4/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.7198 - val_loss: 0.7597\n",
      "Epoch 5/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.7092 - val_loss: 0.7567\n",
      "Epoch 6/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.7039 - val_loss: 0.7613\n",
      "Epoch 7/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6951 - val_loss: 0.7589\n",
      "Epoch 8/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6891 - val_loss: 0.7603\n",
      "Epoch 9/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6875 - val_loss: 0.7633\n",
      "Epoch 10/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6875 - val_loss: 0.7631\n",
      "Epoch 11/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6804 - val_loss: 0.7643\n",
      "Epoch 12/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6824 - val_loss: 0.7648\n",
      "Epoch 13/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6771 - val_loss: 0.7650\n",
      "Epoch 14/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6778 - val_loss: 0.7667\n",
      "Epoch 15/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6743 - val_loss: 0.7659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1633f3860>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train_inputs, y=y_train, \n",
    "    validation_data=(X_test_inputs, y_test),\n",
    "    batch_size=32, epochs=15, \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(n_users, n_movies, join_method='product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"product-%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 1.0752 - val_loss: 0.8866\n",
      "Epoch 2/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.7131 - val_loss: 0.8277\n",
      "Epoch 3/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.4857 - val_loss: 0.8712\n",
      "Epoch 4/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.3877 - val_loss: 0.9002\n",
      "Epoch 5/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.3418 - val_loss: 0.9207\n",
      "Epoch 6/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.3155 - val_loss: 0.9342\n",
      "Epoch 7/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.3006 - val_loss: 0.9455\n",
      "Epoch 8/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.2899 - val_loss: 0.9444\n",
      "Epoch 9/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.2807 - val_loss: 0.9660\n",
      "Epoch 10/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.2770 - val_loss: 0.9569\n",
      "Epoch 11/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.2659 - val_loss: 0.9708\n",
      "Epoch 12/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.2621 - val_loss: 0.9674\n",
      "Epoch 13/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.2580 - val_loss: 0.9773\n",
      "Epoch 14/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.2567 - val_loss: 0.9763\n",
      "Epoch 15/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.2532 - val_loss: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x164264ac8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train_inputs, y=y_train, \n",
    "    validation_data=(X_test_inputs, y_test),\n",
    "    batch_size=32, epochs=15, \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid model with DNN\n",
    "\n",
    "Using movie/user features\n",
    "\n",
    "Interesting approach: https://arxiv.org/pdf/2009.09748.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_weights_fp = os.path.join('.', 'data', 'embeddings.npz')\n",
    "nlp_weights_archive = np.load(nlp_weights_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_weights = np.vstack([\n",
    "    nlp_weights_archive[str(c)] if str(c) in nlp_weights_archive else np.zeros((300,), dtype=np.float32) \n",
    "    for c in movie_encoder.classes_\n",
    "])\n",
    "nlp_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_2(n_users, n_movies, nlp_weights, embedding_size=50, dense_size=10, min_rating=0.0, max_rating=5.0, join_method='concat'):\n",
    "    user = Input(shape=(1, ))\n",
    "    u_emb = Embedding(\n",
    "        n_users, embedding_size, \n",
    "        embeddings_initializer='he_normal',\n",
    "        embeddings_regularizer=l2(1e-6)\n",
    "    )(user)\n",
    "    u_emb = Flatten()(u_emb)\n",
    "    \n",
    "    movie = Input(shape=(1, ))\n",
    "    m_emb = Embedding(\n",
    "        n_movies, embedding_size, \n",
    "        embeddings_initializer='he_normal',\n",
    "        embeddings_regularizer=l2(1e-6)\n",
    "    )(movie)\n",
    "    m_emb = Flatten()(m_emb)\n",
    "    \n",
    "    m_content_emb = Embedding(\n",
    "        nlp_weights.shape[0], nlp_weights.shape[1]\n",
    "    )\n",
    "    m_content_emb.build((1,))\n",
    "    m_content_emb.set_weights([nlp_weights])\n",
    "    m_content_emb.trainable = False\n",
    "    \n",
    "    m_content_emb = m_content_emb(movie)\n",
    "    m_content_emb = Flatten()(m_content_emb)\n",
    "    \n",
    "    if join_method == 'concat':\n",
    "        um = Concatenate()([u_emb, m_emb])\n",
    "    elif join_method == 'product':\n",
    "        um = Multiply()([u_emb, m_emb])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported join method: {join_method}\")\n",
    "    x = Concatenate()([um, m_content_emb])\n",
    "    x = Dropout(0.05)(x)\n",
    "    \n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    # sigmoid output is 0...1 do it must be denormalized to min...max of rating\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    \n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model_2(n_users, n_movies, nlp_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"content-%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.9124 - val_loss: 0.7879\n",
      "Epoch 2/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.7799 - val_loss: 0.7629\n",
      "Epoch 3/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.7403 - val_loss: 0.7602\n",
      "Epoch 4/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.7152 - val_loss: 0.7526\n",
      "Epoch 5/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6982 - val_loss: 0.7561\n",
      "Epoch 6/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.6865 - val_loss: 0.7571\n",
      "Epoch 7/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6748 - val_loss: 0.7622\n",
      "Epoch 8/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6645 - val_loss: 0.7676\n",
      "Epoch 9/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.6588 - val_loss: 0.7660\n",
      "Epoch 10/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6510 - val_loss: 0.7675\n",
      "Epoch 11/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6439 - val_loss: 0.7728\n",
      "Epoch 12/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6413 - val_loss: 0.7803\n",
      "Epoch 13/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6338 - val_loss: 0.7767\n",
      "Epoch 14/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6317 - val_loss: 0.7789\n",
      "Epoch 15/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6253 - val_loss: 0.7775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16488a828>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train_inputs, y=y_train, \n",
    "    validation_data=(X_test_inputs, y_test),\n",
    "    batch_size=32, epochs=15, \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model_2(n_users, n_movies, nlp_weights, join_method='product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"content-prod-%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 1.0950 - val_loss: 0.9181\n",
      "Epoch 2/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.8219 - val_loss: 0.8460\n",
      "Epoch 3/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.6106 - val_loss: 0.8991\n",
      "Epoch 4/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.5223 - val_loss: 0.9048\n",
      "Epoch 5/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.4851 - val_loss: 0.9281\n",
      "Epoch 6/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.4593 - val_loss: 0.9424\n",
      "Epoch 7/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.4430 - val_loss: 0.9341\n",
      "Epoch 8/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.4313 - val_loss: 0.9425\n",
      "Epoch 9/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.4223 - val_loss: 0.9518\n",
      "Epoch 10/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.4104 - val_loss: 0.9344\n",
      "Epoch 11/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.3932 - val_loss: 0.9415\n",
      "Epoch 12/15\n",
      "2679/2679 [==============================] - 7s 3ms/step - loss: 0.3848 - val_loss: 0.9544\n",
      "Epoch 13/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.3796 - val_loss: 0.9612\n",
      "Epoch 14/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.3761 - val_loss: 0.9496\n",
      "Epoch 15/15\n",
      "2679/2679 [==============================] - 8s 3ms/step - loss: 0.3710 - val_loss: 0.9504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1638960b8>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train_inputs, y=y_train, \n",
    "    validation_data=(X_test_inputs, y_test),\n",
    "    batch_size=32, epochs=15, \n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings exploration\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "university",
   "language": "python",
   "name": "university"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
